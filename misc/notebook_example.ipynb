{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Agent Framework in Jupyter Notebook\n",
        "\n",
        "This notebook demonstrates how to use the agent_framework package with structured output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the framework\n",
        "from agent_framework import Agent, LlmClient\n",
        "from pydantic import BaseModel\n",
        "from typing import Literal, List\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define your structured output model\n",
        "class SentimentAnalysis(BaseModel):\n",
        "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
        "    confidence: float\n",
        "    key_phrases: List[str]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create agent with structured output\n",
        "agent = Agent(\n",
        "    model=LlmClient(model=\"gpt-5-mini\"),\n",
        "    tools=[],\n",
        "    instructions=\"Analyze the sentiment of the provided text.\",\n",
        "    output_type=SentimentAnalysis\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment: positive\n",
            "Confidence: 0.95\n",
            "Key phrases: ['exceeded my expectations', 'Highly recommend', 'product']\n"
          ]
        }
      ],
      "source": [
        "# Run the agent\n",
        "result = await agent.run(\"This product exceeded my expectations! Highly recommend.\")\n",
        "\n",
        "# Access structured output\n",
        "print(f\"Sentiment: {result.output.sentiment}\")      # \"positive\"\n",
        "print(f\"Confidence: {result.output.confidence}\")    # 0.92\n",
        "print(f\"Key phrases: {result.output.key_phrases}\")  # [\"exceeded expectations\", \"highly recommend\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "To implement agent, we need tools, execution context, \n",
        "instructions(system prompt that defines agent behavior) and an llm. \n",
        "\n",
        "Event: It is a record of who did what ? like was it user request, \n",
        "or llm requested tool call, or did we get a result back from the tool etc., \n",
        "\n",
        "'''\n",
        "\n",
        "from anyio import Event\n",
        "from agent_framework import ExecutionContext, Message\n",
        "from agent_framework.agent import AgentResult\n",
        "\n",
        "class Agent: ## does this inherit from anything ? \n",
        "    def init(self, tools, executionContext, llmClient, instructions, maxSteps, verbose, name = \"agent\"):\n",
        "        self.tools = self._setup_tools(tools or [])\n",
        "        self.executionContext = executionContext\n",
        "        self.llmClient = llmClient\n",
        "        self.instructions = instructions\n",
        "        self.maxSteps = maxSteps\n",
        "        self.verbose = verbose\n",
        "        self.name = name\n",
        "\n",
        "    ## step 1 is to setup tools\n",
        "\n",
        "    def _setup_tools(self, tools):\n",
        "        return tools\n",
        "\n",
        "    ## step 2 is to define entry point for users.(run method)\n",
        "\n",
        "    async def run(self, user_input, context):\n",
        "\n",
        "        ## check if there is any previous context, else create\n",
        "\n",
        "        if context is None:\n",
        "            context = ExecutionContext()\n",
        "\n",
        "        ## add the user_event to the event\n",
        "        user_event = Event(\n",
        "            execution_id = context.execution_id,\n",
        "            author = 'user',\n",
        "            content = [Message(role = 'user', content = user_input)]\n",
        "        )\n",
        "        ## add the event to context\n",
        "        context.add_event(user_event)\n",
        "\n",
        "        ## if agent doesnt reach final result or max steps, keep performing\n",
        "        while not context.final_result and context.current_step < self.max_steps:\n",
        "            ## each step is a think-act cycle\n",
        "            await self.step(context)\n",
        "\n",
        "            ## check if newly performed action is final\n",
        "            last_event = context.events[-1]\n",
        "\n",
        "            # If it is final, then extract the last event and sent it to \n",
        "            # Agent result along with the context\n",
        "            if self._is_final_response(last_event):\n",
        "                context.final_result = self._extract_final_result(last_event)\n",
        "\n",
        "        return AgentResult(context.final_result, context = context)\n",
        "\n",
        "    # step 3 prepare for llm request\n",
        "\n",
        "    def _prepare_llm_request(self, context):\n",
        "        \n",
        "        #flatten all the events (why ?)\n",
        "        flat_contents = []\n",
        "        for event in context.events:\n",
        "            flat_contents.extend(event.content)\n",
        "\n",
        "        ## with this context, call llm\n",
        "        return LlmRequest(\n",
        "        instructions=[self.instructions] if self.instructions else [],\n",
        "        contents=flat_contents,\n",
        "        tools=self.tools,\n",
        "        tool_choice=\"auto\" if self.tools else None,\n",
        "    )\n",
        "\n",
        "    async def step(self, context):\n",
        "        \n",
        "        ## write a method for this\n",
        "        llm_request = self._prepare_llm_request(context)\n",
        "\n",
        "        # Get LLM's decision\n",
        "        llm_response = await self.think(llm_request)\n",
        "\n",
        "        response_event = Event(\n",
        "            execution_id=context.execution_id,\n",
        "            author=self.name,\n",
        "            content=llm_response.content,\n",
        "        )\n",
        "\n",
        "    async def think(self, llm_request):\n",
        "        \"\"\"Get LLM's response/decision.\"\"\"\n",
        "        return await self.model.generate(llm_request)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q. LLM Request? \n",
        "\n",
        "A. It goes from our agent to LLM call. before sending it, we bundle it with necessary context , prompt and tools."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
